# ==========================================
# Lab 2 â€” Qdrant Production RAG Environment
# ==========================================


# ------------------------------------------
# EDGE AUTHENTICATION (REQUIRED)
# ------------------------------------------
# This key is enforced by NGINX before any
# request reaches the ingestion API.
#
# Generate one with:
#   openssl rand -hex 32
#
# Example:
# EDGE_API_KEY=4f3c2b1a9e8d7c6b5a4f3c2b1a9e8d7c6b5a4f3c2b1a9e8d7c6b5a4f3c2b1a

EDGE_API_KEY=replace-with-long-random-value


# ------------------------------------------
# OLLAMA SETTINGS
# ------------------------------------------
# Recommended lightweight default:
# llama3.2:1b
#
# Larger (more capable but heavier):
# llama3.1:8b-instruct

OLLAMA_MODEL=llama3.2:1b
OLLAMA_BASE_URL=http://ollama:11434


# ------------------------------------------
# QDRANT SETTINGS
# ------------------------------------------
# Collection name used in this lab

QDRANT_COLLECTION=LabDoc

# Internal service URL (do not change unless
# modifying docker-compose networking)

QDRANT_URL=http://qdrant:6333


# ------------------------------------------
# EMBEDDINGS SERVICE (TEI)
# ------------------------------------------
# Model served by text-embeddings-inference
# CPU-friendly and small:
# sentence-transformers/all-MiniLM-L6-v2

EMBEDDINGS_MODEL_ID=sentence-transformers/all-MiniLM-L6-v2

# Vector dimension for that model
# all-MiniLM-L6-v2 = 384

EMBEDDINGS_DIM=384

# Internal URL for embeddings service



# ------------------------------------------
# RAG TUNING SETTINGS
# ------------------------------------------
# Number of documents retrieved
# before prompt construction

RAG_TOP_K=5

# Max characters per source included
# in the prompt (controls prompt size)

RAG_MAX_SOURCE_CHARS=1200
QDRANT_COLLECTION=LabDoc
EMBEDDINGS_MODEL_ID=sentence-transformers/all-MiniLM-L6-v2
EMBEDDINGS_DIM=384
